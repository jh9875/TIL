Part 1. 들어가며
===

(여기엔 크게 많은 내용이 없어서 한꺼번에 간단히만 정리.)

<br/>

### 데이터 엔지니어링이란

데이터 기반 프로젝트들이 돌아가기 위해선 데이터 엔지니어링이 필요.

데이터를 이용해서 인사이트를 추출하는 업무의 대부분은 데이터 엔지니어링을 사용.


*Garbage In Garbage Out* : 복잡한 데이터 모델을 만드는 것 보단 좋은 데이터를 모으고 잘 관리하는 것이 훨씬 효율적으로 성과를 내는 방법 <br/>
=> 데이터 엔지니어링 사용.

<br/>

### 엔지니어링 아키텍처

과거의 데이터 관리
- 스키마를 미리 만들어 사용. (변동이 별로 없기 때문)
- ETL 사용 (Extract / Transform / Load)

데이터의 활용이 다양해지면서 과거의 방법이 불편해짐 <br>
=> 실시간성을 요구하는 기능 <br>
=> 빨빨라지는 기능 추가 <br>
=> 실시간 로그 <br>
=> 비정형 데이터 <br>
=> 서드 파티 데이터 <br>

현재 데이터 관리 <br>
ETL에서 ELT로 변환. <br>
데이터 추출(E) / 일단 저장 (L) / 쓰임새에 따라 변환 (T)

데이터 인프라 트랜드
- 실시간 빅데이터 처리 (Stream Processing)
- ETL -> ELT
- Dataflow 자동화
- ..

데이터 기반 프로젝트에서 <br>
일반적인 데이터 엔지니어링은 "수집 및 변환"과 "데이터 처리"에 집중

해당 강의에서 사용할 도구
- Spark : 데이터 병렬-분산 처리
- Airflow : 데이터 오케스트레이션
- Kafka : 이벤트 스트리밍
- Flink : 분산 스트림 프로세싱

<br/>

### Batch & Stream Processing

**배치 프로세싱** : 일괄 처리 <br>
많은 양의 데이터를 *정해진 시간*에 *한꺼번에* 처리하는 것
1. 한정된 대량의 데이터
2. 특정 시간
3. 일괄 처리

배치 프로세싱 사용 <br>
- 실시간성을 보장하지 않아도 될 때
- 무거운 처리를 할때 (ex : ML 학습)

**스트림 프로세싱** : 실시간으로 데이터를 계속 처리하는 것.

스트림 프로세싱 사용 <br>
- 실시간성을 보장해야 될 때
- 데이터가 여러 소스로부터 들어올 때
- 데이터가 가끔 들어오거나 지속적으로 들어올 때
- 가벼운 처리를 할때

일반적인 배치 처리 플로우
1. 데이터를 모아서
2. 데이터베이스에서 읽어서 처리
3. 다시 데이터베이스에 담기

일반적인 스트림 처리 플로우
1. 데이터가 들어올때마다 (ingest)
2. 쿼리/처리 후 State를 업데이트
3. DB에 담기

<br/>

### Dataflow Orchestration

데이터 테스크를 지휘하는 느낌
- 테스크 스케줄링
- 분산 실행
- 테스크간 의존성 관리

서비스가 커짐에따라 데이터 플랫폼의 복잡도가 커짐, 테스크간 의존성이 커짐에 따라 오케스트레이션이 필요.

